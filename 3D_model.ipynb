{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "from ipywidgets import IntSlider, interact\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.patches import PathPatch, Rectangle\n",
    "from matplotlib.path import Path\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import (BatchNormalization, Conv3D, Dense,\n",
    "                                     Dropout, GlobalAveragePooling3D,\n",
    "                                     MaxPool3D)\n",
    "from keras.optimizers import Adam\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import keras_applications_3d as ka3d\n",
    "from keras_applications_3d import vgg16, vgg19, resnet, resnet_v2, densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
    "    return volume.astype('float32')\n",
    "\n",
    "def resize_volume(img, desired_width=128, desired_height=128, desired_depth=64):\n",
    "    \"\"\"Resize the volume\"\"\"\n",
    "    # Compute zoom factors\n",
    "    width_factor = desired_width / img.shape[0]\n",
    "    height_factor = desired_height / img.shape[1]\n",
    "    depth_factor = desired_depth / img.shape[-1]\n",
    "    # Rotate volume by 90 degrees\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize the volume using spline interpolated zoom (SIZ)\n",
    "    img = zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - functions to load data and labels\n",
    "\n",
    "# print(f'Number of \n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - build train, validation, test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données originales sont représentées sous la forme de tenseurs tridimensionnels avec des dimensions (samples, height, width, depth). Cependant, afin de permettre l'utilisation de convolutions 3D sur ces données, nous devons ajouter une dimension supplémentaire à nos tenseurs. Cette dimension est ajoutée à l'axe 4, qui représente le nombre de canaux. En général quand on traite des images 2D en couleurs on a 3 canaux pour le RGB, ici on traite des images 3D en pseudo NB. Donc en ajoutant une dimension, les données sont transformées en tenseurs de forme (samples, height, width, depth, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Add a dimension to the data to make it 4D (for the channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Add data augmentation (rotation, translation, scaling, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Build train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmented CT Scan Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Check the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - MRI images are composed by many slices, build a montage of the them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3D-ResNet50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 113, 137, 113,    0         \n",
      "                             1)]                                 \n",
      "                                                                 \n",
      " block1_conv1 (Conv3D)       (None, 113, 137, 113, 1   448       \n",
      "                             6)                                  \n",
      "                                                                 \n",
      " block1_conv2 (Conv3D)       (None, 113, 137, 113, 1   6928      \n",
      "                             6)                                  \n",
      "                                                                 \n",
      " block1_pool (MaxPooling3D)  (None, 56, 68, 56, 16)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv3D)       (None, 56, 68, 56, 32)    13856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv3D)       (None, 56, 68, 56, 32)    27680     \n",
      "                                                                 \n",
      " block2_pool (MaxPooling3D)  (None, 28, 34, 28, 32)    0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv3D)       (None, 28, 34, 28, 64)    55360     \n",
      "                                                                 \n",
      " block3_conv2 (Conv3D)       (None, 28, 34, 28, 64)    110656    \n",
      "                                                                 \n",
      " block3_conv3 (Conv3D)       (None, 28, 34, 28, 64)    110656    \n",
      "                                                                 \n",
      " block3_conv4 (Conv3D)       (None, 28, 34, 28, 64)    110656    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling3D)  (None, 14, 17, 14, 64)    0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv3D)       (None, 14, 17, 14, 128)   221312    \n",
      "                                                                 \n",
      " block4_conv2 (Conv3D)       (None, 14, 17, 14, 128)   442496    \n",
      "                                                                 \n",
      " block4_conv3 (Conv3D)       (None, 14, 17, 14, 128)   442496    \n",
      "                                                                 \n",
      " block4_conv4 (Conv3D)       (None, 14, 17, 14, 128)   442496    \n",
      "                                                                 \n",
      " block4_pool (MaxPooling3D)  (None, 7, 8, 7, 128)      0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv3D)       (None, 7, 8, 7, 128)      442496    \n",
      "                                                                 \n",
      " block5_conv2 (Conv3D)       (None, 7, 8, 7, 128)      442496    \n",
      "                                                                 \n",
      " block5_conv3 (Conv3D)       (None, 7, 8, 7, 128)      442496    \n",
      "                                                                 \n",
      " block5_conv4 (Conv3D)       (None, 7, 8, 7, 128)      442496    \n",
      "                                                                 \n",
      " block5_pool (MaxPooling3D)  (None, 3, 4, 3, 128)      0         \n",
      "                                                                 \n",
      " global_average_pooling3d_2  (None, 128)               0         \n",
      "  (GlobalAveragePooling3D)                                       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3779922 (14.42 MB)\n",
      "Trainable params: 3779922 (14.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(height=113, width=137, depth=113):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "    \n",
    "    net = vgg19.VGG19(\n",
    "        input_shape=(height, width, depth, 1),\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        classes=nb_classes,\n",
    "        base_channel=16\n",
    "    )\n",
    "    \n",
    "    x = net.layers[-1].output\n",
    "    x = GlobalAveragePooling3D()(x)    \n",
    "    x = Dense(units=128, activation='relu')(x)\n",
    "    x = Dense(units=64, activation='relu')(x)\n",
    "    outputs = Dense(units=nb_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(net.inputs, outputs, name='3D-ResNet50')\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(height=113, width=137, depth=113)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=['acc'],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "# model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate(['acc', 'loss']):\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[f'val_{metric}'])\n",
    "    ax[i].set_title(f'Model {metric}')\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Evaluate the model on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
